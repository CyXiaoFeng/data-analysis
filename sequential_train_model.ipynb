{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 生成示例数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 生成示例数据\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(1000, 10)  # 1000个样本，每个样本有10个特征\n",
    "y = np.random.randint(0, 2, size=1000)  # 二分类标签，0或1\n",
    "\n",
    "# 将数据保存到DataFrame中\n",
    "data = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(1, 11)])\n",
    "data['target'] = y\n",
    "\n",
    "# 保存数据到CSV文件\n",
    "data.to_csv('example_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(709, 131)\n",
      "[[ 1.08390342  1.38498757 -0.75780429 ...  0.70659736 -0.10815092\n",
      "   0.84011998]\n",
      " [-0.92259142 -0.70521717 -0.72745559 ... -0.14768158 -0.18485242\n",
      "  -0.4515663 ]\n",
      " [-0.92259142 -0.70521717  0.94931    ... -0.1037773   0.9584246\n",
      "  -0.56689339]\n",
      " ...\n",
      " [-0.92259142 -0.15516329  1.83195131 ... -0.86260966  0.12100491\n",
      "  -0.84171389]\n",
      " [-0.92259142 -1.58530338 -0.32280628 ...  0.62418499 -0.38311137\n",
      "  -0.10307029]\n",
      " [ 1.08390342 -0.5952064   0.34739414 ... 11.67144906  0.93634662\n",
      "   7.65554602]]\n"
     ]
    }
   ],
   "source": [
    "# 2. 加载数据并预处理\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 加载数据\n",
    "df1 = pd.read_csv('RESULT.oa.csv')\n",
    "df2 = pd.read_csv('RESULT.non oa.csv')\n",
    "data = pd.concat([df1, df2], axis=0)  # axis=0表示垂直堆叠，axis=1表示水平堆叠\n",
    "print(data.shape)\n",
    "# 分割特征和标签\n",
    "X = data.drop('label', axis=1).values\n",
    "y = data['label'].values\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 分割训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "降维后的特征数: 31\n"
     ]
    }
   ],
   "source": [
    "# 3. 使用PCA进行降维\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "# 使用PCA\n",
    "pca = PCA()# 使用PCA进行降维\n",
    "pca = PCA(n_components=0.95, random_state=42)  # 选择保留95%方差的主成分\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# 输出降维后的特征数\n",
    "print(f\"降维后的特征数: {X_train_pca.shape[1]}\")  # 输出降维后的维度数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 64)                2048      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4161 (16.25 KB)\n",
      "Trainable params: 4161 (16.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 4s 40ms/step - loss: 0.7604 - accuracy: 0.5386 - val_loss: 0.7317 - val_accuracy: 0.6053\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.7395 - accuracy: 0.5651 - val_loss: 0.7157 - val_accuracy: 0.6228\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.7194 - accuracy: 0.5784 - val_loss: 0.7043 - val_accuracy: 0.6404\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.7036 - accuracy: 0.5740 - val_loss: 0.6934 - val_accuracy: 0.6404\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5938 - val_loss: 0.6845 - val_accuracy: 0.6404\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6773 - accuracy: 0.6026 - val_loss: 0.6757 - val_accuracy: 0.6228\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6653 - accuracy: 0.6093 - val_loss: 0.6697 - val_accuracy: 0.6316\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6549 - accuracy: 0.6203 - val_loss: 0.6635 - val_accuracy: 0.6316\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6452 - accuracy: 0.6313 - val_loss: 0.6578 - val_accuracy: 0.6316\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.6355 - accuracy: 0.6490 - val_loss: 0.6520 - val_accuracy: 0.6228\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6272 - accuracy: 0.6490 - val_loss: 0.6463 - val_accuracy: 0.6228\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6193 - accuracy: 0.6689 - val_loss: 0.6415 - val_accuracy: 0.6228\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6117 - accuracy: 0.6799 - val_loss: 0.6380 - val_accuracy: 0.6316\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.6047 - accuracy: 0.6909 - val_loss: 0.6336 - val_accuracy: 0.6491\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5975 - accuracy: 0.6909 - val_loss: 0.6302 - val_accuracy: 0.6316\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5908 - accuracy: 0.7042 - val_loss: 0.6262 - val_accuracy: 0.6228\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5843 - accuracy: 0.7086 - val_loss: 0.6231 - val_accuracy: 0.6316\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5785 - accuracy: 0.7152 - val_loss: 0.6203 - val_accuracy: 0.6491\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5729 - accuracy: 0.7108 - val_loss: 0.6184 - val_accuracy: 0.6491\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5675 - accuracy: 0.7263 - val_loss: 0.6156 - val_accuracy: 0.6491\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5623 - accuracy: 0.7329 - val_loss: 0.6128 - val_accuracy: 0.6491\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5570 - accuracy: 0.7417 - val_loss: 0.6105 - val_accuracy: 0.6491\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5522 - accuracy: 0.7439 - val_loss: 0.6070 - val_accuracy: 0.6491\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5475 - accuracy: 0.7483 - val_loss: 0.6052 - val_accuracy: 0.6579\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5430 - accuracy: 0.7461 - val_loss: 0.6027 - val_accuracy: 0.6579\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5381 - accuracy: 0.7528 - val_loss: 0.5996 - val_accuracy: 0.6579\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5333 - accuracy: 0.7528 - val_loss: 0.5963 - val_accuracy: 0.6579\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5288 - accuracy: 0.7594 - val_loss: 0.5936 - val_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5242 - accuracy: 0.7660 - val_loss: 0.5922 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5203 - accuracy: 0.7748 - val_loss: 0.5901 - val_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.7748 - val_loss: 0.5885 - val_accuracy: 0.6754\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5122 - accuracy: 0.7770 - val_loss: 0.5878 - val_accuracy: 0.6754\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.5083 - accuracy: 0.7792 - val_loss: 0.5857 - val_accuracy: 0.6842\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5046 - accuracy: 0.7815 - val_loss: 0.5830 - val_accuracy: 0.6842\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5009 - accuracy: 0.7837 - val_loss: 0.5807 - val_accuracy: 0.6842\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4974 - accuracy: 0.7859 - val_loss: 0.5793 - val_accuracy: 0.6930\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4937 - accuracy: 0.7881 - val_loss: 0.5780 - val_accuracy: 0.7105\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.4909 - accuracy: 0.7903 - val_loss: 0.5775 - val_accuracy: 0.7105\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.4872 - accuracy: 0.7947 - val_loss: 0.5746 - val_accuracy: 0.7105\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4842 - accuracy: 0.7947 - val_loss: 0.5720 - val_accuracy: 0.7105\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4810 - accuracy: 0.7925 - val_loss: 0.5704 - val_accuracy: 0.7105\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4779 - accuracy: 0.7991 - val_loss: 0.5698 - val_accuracy: 0.7105\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4748 - accuracy: 0.7991 - val_loss: 0.5677 - val_accuracy: 0.7105\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4720 - accuracy: 0.7991 - val_loss: 0.5655 - val_accuracy: 0.7018\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4691 - accuracy: 0.8057 - val_loss: 0.5639 - val_accuracy: 0.7018\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.4666 - accuracy: 0.8057 - val_loss: 0.5640 - val_accuracy: 0.6842\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.4638 - accuracy: 0.8079 - val_loss: 0.5623 - val_accuracy: 0.6842\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4607 - accuracy: 0.8102 - val_loss: 0.5620 - val_accuracy: 0.6842\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4583 - accuracy: 0.8102 - val_loss: 0.5608 - val_accuracy: 0.6842\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4554 - accuracy: 0.8102 - val_loss: 0.5596 - val_accuracy: 0.6842\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4530 - accuracy: 0.8124 - val_loss: 0.5592 - val_accuracy: 0.6842\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4505 - accuracy: 0.8146 - val_loss: 0.5601 - val_accuracy: 0.6930\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4482 - accuracy: 0.8146 - val_loss: 0.5586 - val_accuracy: 0.6930\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4453 - accuracy: 0.8168 - val_loss: 0.5569 - val_accuracy: 0.6930\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4431 - accuracy: 0.8190 - val_loss: 0.5557 - val_accuracy: 0.7018\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4407 - accuracy: 0.8146 - val_loss: 0.5545 - val_accuracy: 0.7018\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4381 - accuracy: 0.8190 - val_loss: 0.5531 - val_accuracy: 0.6930\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.4358 - accuracy: 0.8212 - val_loss: 0.5508 - val_accuracy: 0.6930\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4336 - accuracy: 0.8190 - val_loss: 0.5496 - val_accuracy: 0.6930\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.4314 - accuracy: 0.8190 - val_loss: 0.5494 - val_accuracy: 0.6930\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4293 - accuracy: 0.8190 - val_loss: 0.5491 - val_accuracy: 0.6930\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4271 - accuracy: 0.8212 - val_loss: 0.5467 - val_accuracy: 0.6842\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4250 - accuracy: 0.8212 - val_loss: 0.5460 - val_accuracy: 0.6842\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4230 - accuracy: 0.8234 - val_loss: 0.5445 - val_accuracy: 0.6930\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4210 - accuracy: 0.8212 - val_loss: 0.5453 - val_accuracy: 0.6842\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.8256 - val_loss: 0.5455 - val_accuracy: 0.6842\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.8234 - val_loss: 0.5434 - val_accuracy: 0.6842\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8278 - val_loss: 0.5415 - val_accuracy: 0.6754\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4130 - accuracy: 0.8278 - val_loss: 0.5414 - val_accuracy: 0.6754\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.4112 - accuracy: 0.8300 - val_loss: 0.5408 - val_accuracy: 0.6754\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.4090 - accuracy: 0.8300 - val_loss: 0.5412 - val_accuracy: 0.6842\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4070 - accuracy: 0.8322 - val_loss: 0.5408 - val_accuracy: 0.6842\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4053 - accuracy: 0.8322 - val_loss: 0.5400 - val_accuracy: 0.6842\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4034 - accuracy: 0.8322 - val_loss: 0.5404 - val_accuracy: 0.6842\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4019 - accuracy: 0.8322 - val_loss: 0.5405 - val_accuracy: 0.6842\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4001 - accuracy: 0.8344 - val_loss: 0.5391 - val_accuracy: 0.6842\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.8366 - val_loss: 0.5377 - val_accuracy: 0.6842\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.3964 - accuracy: 0.8322 - val_loss: 0.5380 - val_accuracy: 0.6842\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3947 - accuracy: 0.8322 - val_loss: 0.5378 - val_accuracy: 0.6930\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3929 - accuracy: 0.8344 - val_loss: 0.5378 - val_accuracy: 0.7018\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3912 - accuracy: 0.8389 - val_loss: 0.5368 - val_accuracy: 0.6930\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3894 - accuracy: 0.8389 - val_loss: 0.5362 - val_accuracy: 0.6930\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3882 - accuracy: 0.8389 - val_loss: 0.5343 - val_accuracy: 0.7018\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.3869 - accuracy: 0.8411 - val_loss: 0.5347 - val_accuracy: 0.6930\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.3848 - accuracy: 0.8455 - val_loss: 0.5351 - val_accuracy: 0.6930\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3829 - accuracy: 0.8455 - val_loss: 0.5373 - val_accuracy: 0.6930\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3812 - accuracy: 0.8477 - val_loss: 0.5375 - val_accuracy: 0.6842\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3798 - accuracy: 0.8455 - val_loss: 0.5369 - val_accuracy: 0.6842\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.3783 - accuracy: 0.8433 - val_loss: 0.5370 - val_accuracy: 0.6930\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.3768 - accuracy: 0.8433 - val_loss: 0.5366 - val_accuracy: 0.6930\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.3754 - accuracy: 0.8455 - val_loss: 0.5404 - val_accuracy: 0.6930\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3740 - accuracy: 0.8521 - val_loss: 0.5394 - val_accuracy: 0.6930\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3723 - accuracy: 0.8477 - val_loss: 0.5373 - val_accuracy: 0.6930\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3711 - accuracy: 0.8477 - val_loss: 0.5359 - val_accuracy: 0.6930\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3700 - accuracy: 0.8455 - val_loss: 0.5354 - val_accuracy: 0.6930\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.3682 - accuracy: 0.8477 - val_loss: 0.5368 - val_accuracy: 0.6930\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3669 - accuracy: 0.8499 - val_loss: 0.5363 - val_accuracy: 0.7018\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.3656 - accuracy: 0.8499 - val_loss: 0.5382 - val_accuracy: 0.6930\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.3640 - accuracy: 0.8477 - val_loss: 0.5373 - val_accuracy: 0.7018\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.3634 - accuracy: 0.8521 - val_loss: 0.5363 - val_accuracy: 0.7018\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6433 - accuracy: 0.7324\n",
      "Test accuracy: 0.7323943376541138\n"
     ]
    }
   ],
   "source": [
    "# 4. 构建和训练神经网络模型\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam  # 确保正确导入\n",
    "# 定义神经网络模型\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_pca.shape[1],)))  # 更新输入层形状为降维后的特征数\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # 二分类任务，使用sigmoid作为输出层激活函数\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(X_train_pca, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate(X_test_pca, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# 保存模型\n",
    "model.save('my_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step\n",
      "[[0.6083752 ]\n",
      " [0.0683864 ]\n",
      " [0.8943182 ]\n",
      " [0.8134248 ]\n",
      " [0.993692  ]\n",
      " [0.67131513]\n",
      " [0.89567095]\n",
      " [0.31867954]\n",
      " [0.8799629 ]\n",
      " [0.8930397 ]\n",
      " [0.9967328 ]\n",
      " [0.59705687]\n",
      " [0.3455385 ]\n",
      " [0.9832154 ]\n",
      " [0.8611443 ]\n",
      " [0.93167776]\n",
      " [0.91859156]\n",
      " [0.6368263 ]\n",
      " [0.952737  ]\n",
      " [0.5157976 ]\n",
      " [0.9515654 ]\n",
      " [0.46502864]\n",
      " [0.9759738 ]\n",
      " [0.9585403 ]\n",
      " [0.9694546 ]\n",
      " [0.96262956]\n",
      " [0.7463692 ]\n",
      " [0.4618582 ]\n",
      " [0.89524907]\n",
      " [0.9122158 ]\n",
      " [0.33624956]\n",
      " [0.6857974 ]\n",
      " [0.91090816]\n",
      " [0.46149263]\n",
      " [0.814458  ]\n",
      " [0.5611928 ]\n",
      " [0.7805537 ]\n",
      " [0.98335695]\n",
      " [0.99581105]\n",
      " [0.5429908 ]\n",
      " [0.5614386 ]\n",
      " [0.34241372]\n",
      " [0.2981437 ]\n",
      " [0.76012754]\n",
      " [0.27912122]\n",
      " [0.8865684 ]\n",
      " [0.8695651 ]\n",
      " [0.42888278]\n",
      " [0.90668243]\n",
      " [0.90119034]\n",
      " [0.9564345 ]\n",
      " [0.964107  ]\n",
      " [0.8425451 ]\n",
      " [0.9196303 ]\n",
      " [0.17885415]\n",
      " [0.67137855]\n",
      " [0.34680757]\n",
      " [0.6546323 ]\n",
      " [0.60506797]\n",
      " [0.9201752 ]\n",
      " [0.8845589 ]\n",
      " [0.81830984]\n",
      " [0.9613549 ]\n",
      " [0.68003625]\n",
      " [0.42965266]\n",
      " [0.81015325]\n",
      " [0.66020024]\n",
      " [0.7865479 ]\n",
      " [0.18351959]\n",
      " [0.6201296 ]\n",
      " [0.06525801]\n",
      " [0.14953096]\n",
      " [0.1805128 ]\n",
      " [0.63164705]\n",
      " [0.70075554]\n",
      " [0.17244557]\n",
      " [0.8884058 ]\n",
      " [0.66579455]\n",
      " [0.43682924]\n",
      " [0.9783138 ]\n",
      " [0.30222383]\n",
      " [0.99295   ]\n",
      " [0.84316635]\n",
      " [0.9932917 ]\n",
      " [0.08312285]\n",
      " [0.3904066 ]\n",
      " [0.12333404]\n",
      " [0.95543945]\n",
      " [0.76541585]\n",
      " [0.96439725]\n",
      " [0.9773096 ]\n",
      " [0.54966986]\n",
      " [0.67323494]\n",
      " [0.6227039 ]\n",
      " [0.87902635]\n",
      " [0.6214552 ]\n",
      " [0.9731079 ]\n",
      " [0.6348297 ]\n",
      " [0.41974446]\n",
      " [0.6781728 ]\n",
      " [0.9911812 ]\n",
      " [0.5932422 ]\n",
      " [0.3004528 ]\n",
      " [0.76398796]\n",
      " [0.26412663]\n",
      " [0.7422756 ]\n",
      " [0.4660248 ]\n",
      " [0.5498059 ]\n",
      " [0.6965    ]\n",
      " [0.8310111 ]\n",
      " [0.5728552 ]\n",
      " [0.8901761 ]\n",
      " [0.9216856 ]\n",
      " [0.41435167]\n",
      " [0.8228193 ]\n",
      " [0.8789144 ]\n",
      " [0.98403174]\n",
      " [0.70943207]\n",
      " [0.83603525]\n",
      " [0.8740844 ]\n",
      " [0.67365825]\n",
      " [0.6671918 ]\n",
      " [0.63277215]\n",
      " [0.98067963]\n",
      " [0.7065486 ]\n",
      " [0.90654624]\n",
      " [0.70150805]\n",
      " [0.9547899 ]\n",
      " [0.83023316]\n",
      " [0.35136718]\n",
      " [0.6168043 ]\n",
      " [0.87310946]\n",
      " [0.2847224 ]\n",
      " [0.35807893]\n",
      " [0.45158702]\n",
      " [0.58713007]\n",
      " [0.7864526 ]\n",
      " [0.9989548 ]\n",
      " [0.80326813]\n",
      " [0.95664215]\n",
      " [0.8942489 ]\n",
      " [0.2183247 ]\n",
      " [0.31328455]\n",
      " [0.29992005]\n",
      " [0.40387592]\n",
      " [0.6813843 ]\n",
      " [0.845243  ]\n",
      " [0.7402524 ]\n",
      " [0.9550726 ]\n",
      " [0.34260264]\n",
      " [0.37132043]\n",
      " [0.40014905]\n",
      " [0.3002497 ]\n",
      " [0.81227964]\n",
      " [0.86773235]\n",
      " [0.3890088 ]\n",
      " [0.28473762]\n",
      " [0.6438378 ]\n",
      " [0.5402954 ]\n",
      " [0.8734782 ]\n",
      " [0.16538985]\n",
      " [0.93273574]\n",
      " [0.8985997 ]\n",
      " [0.5610534 ]\n",
      " [0.99332577]\n",
      " [0.86426985]\n",
      " [0.51571316]\n",
      " [0.49324438]\n",
      " [0.2052828 ]\n",
      " [0.7708253 ]\n",
      " [0.6102769 ]\n",
      " [0.5163453 ]\n",
      " [0.91511875]\n",
      " [0.8619497 ]\n",
      " [0.9693184 ]\n",
      " [0.87056106]\n",
      " [0.879989  ]\n",
      " [0.939035  ]\n",
      " [0.79120046]\n",
      " [0.26562098]\n",
      " [0.5027144 ]\n",
      " [0.960061  ]\n",
      " [0.96547353]\n",
      " [0.99696136]\n",
      " [0.90933436]\n",
      " [0.7820388 ]\n",
      " [0.9196961 ]\n",
      " [0.9927321 ]\n",
      " [0.7503719 ]\n",
      " [0.9339984 ]\n",
      " [0.91602397]\n",
      " [0.8291512 ]\n",
      " [0.9708078 ]\n",
      " [0.81461084]\n",
      " [0.91302335]\n",
      " [0.8613655 ]\n",
      " [0.9728449 ]\n",
      " [0.93403417]\n",
      " [0.9437406 ]\n",
      " [0.3773498 ]\n",
      " [0.7354268 ]\n",
      " [0.4064193 ]\n",
      " [0.9006134 ]\n",
      " [0.72922784]\n",
      " [0.95458543]\n",
      " [0.51801693]\n",
      " [0.4147722 ]\n",
      " [0.79944676]\n",
      " [0.67970604]\n",
      " [0.43050003]\n",
      " [0.29350245]\n",
      " [0.8949235 ]\n",
      " [0.7873182 ]\n",
      " [0.8812199 ]\n",
      " [0.5077368 ]\n",
      " [0.99903744]\n",
      " [0.32829002]\n",
      " [0.93326974]\n",
      " [0.67469174]\n",
      " [0.9340449 ]\n",
      " [0.6350559 ]\n",
      " [0.62761897]\n",
      " [0.84273386]\n",
      " [0.78565925]\n",
      " [0.94677   ]\n",
      " [0.7597358 ]\n",
      " [0.37535378]\n",
      " [0.5959658 ]\n",
      " [0.96152085]\n",
      " [0.8133884 ]\n",
      " [0.72681165]\n",
      " [0.9056462 ]\n",
      " [0.9795915 ]\n",
      " [0.76350766]\n",
      " [0.57136434]\n",
      " [0.17309244]\n",
      " [0.45471084]\n",
      " [0.6822586 ]\n",
      " [0.9175139 ]\n",
      " [0.56293565]\n",
      " [0.47911346]\n",
      " [0.85999006]\n",
      " [0.29970014]\n",
      " [0.670036  ]\n",
      " [0.5723084 ]\n",
      " [0.31093532]\n",
      " [0.5553434 ]\n",
      " [0.5655133 ]\n",
      " [0.8240662 ]\n",
      " [0.30105624]\n",
      " [0.49848157]\n",
      " [0.35543793]\n",
      " [0.26114428]\n",
      " [0.8443647 ]\n",
      " [0.900975  ]\n",
      " [0.77126515]\n",
      " [0.8963879 ]\n",
      " [0.2887954 ]\n",
      " [0.47212514]\n",
      " [0.8832708 ]\n",
      " [0.57995343]\n",
      " [0.8071062 ]\n",
      " [0.94476795]\n",
      " [0.17305437]\n",
      " [0.0980722 ]\n",
      " [0.72121656]\n",
      " [0.98509556]\n",
      " [0.9348642 ]\n",
      " [0.9766411 ]\n",
      " [0.29270774]\n",
      " [0.9333614 ]\n",
      " [0.92266876]\n",
      " [0.7634112 ]\n",
      " [0.41447908]\n",
      " [0.51216716]\n",
      " [0.8429571 ]\n",
      " [0.7367909 ]\n",
      " [0.76308554]\n",
      " [0.42968765]\n",
      " [0.6890724 ]\n",
      " [0.65028673]\n",
      " [0.7690665 ]\n",
      " [0.5232497 ]\n",
      " [0.71266335]\n",
      " [0.80173296]\n",
      " [0.9706544 ]\n",
      " [0.3137472 ]\n",
      " [0.79160833]\n",
      " [0.90480673]\n",
      " [0.276586  ]\n",
      " [0.74325705]\n",
      " [0.9891492 ]\n",
      " [0.7451534 ]\n",
      " [0.78264713]\n",
      " [0.7091283 ]\n",
      " [0.8343551 ]\n",
      " [0.40315706]\n",
      " [0.9795968 ]\n",
      " [0.17266183]\n",
      " [0.8849603 ]\n",
      " [0.44748297]\n",
      " [0.6630689 ]\n",
      " [0.5655214 ]\n",
      " [0.64037454]\n",
      " [0.595287  ]\n",
      " [0.6834406 ]\n",
      " [0.7133172 ]\n",
      " [0.7295714 ]\n",
      " [0.95356333]\n",
      " [0.7007275 ]\n",
      " [0.49408174]\n",
      " [0.53992856]\n",
      " [0.16907646]\n",
      " [0.26244164]\n",
      " [0.27769753]\n",
      " [0.84757686]\n",
      " [0.9856347 ]\n",
      " [0.89754367]\n",
      " [0.8156478 ]\n",
      " [0.9691067 ]\n",
      " [0.887163  ]\n",
      " [0.83851516]\n",
      " [0.7531388 ]\n",
      " [0.7939919 ]\n",
      " [0.88535   ]\n",
      " [0.9158508 ]\n",
      " [0.6527972 ]\n",
      " [0.87858015]\n",
      " [0.31080043]\n",
      " [0.9822173 ]\n",
      " [0.7700264 ]\n",
      " [0.542178  ]\n",
      " [0.78446275]\n",
      " [0.54585594]\n",
      " [0.99040675]\n",
      " [0.6174439 ]\n",
      " [0.37787837]\n",
      " [0.47614905]\n",
      " [0.846446  ]\n",
      " [0.38383377]\n",
      " [0.6588997 ]\n",
      " [0.68818235]\n",
      " [0.6736948 ]\n",
      " [0.34734195]\n",
      " [0.7333518 ]\n",
      " [0.6464523 ]]\n"
     ]
    }
   ],
   "source": [
    "#  加载 Keras 本地格式的模型\n",
    "model = tf.keras.models.load_model('my_model.keras')\n",
    "\n",
    "# 生成一些新的示例数据（这里假设有新的数据）\n",
    "X_new = pd.read_csv(\"RESULT.oa.csv\")  # 5个样本，每个样本有130个特征\n",
    "\n",
    "X = X_new.drop('label', axis=1).values\n",
    "\n",
    "# 数据标准化（使用之前的scaler）\n",
    "X_new_scaled = scaler.transform(X)\n",
    "\n",
    "# PCA降维（使用之前的PCA）\n",
    "X_new_pca = pca.transform(X_new_scaled)\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = model.predict(X_new_pca)\n",
    "\n",
    "# 输出预测结果\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
